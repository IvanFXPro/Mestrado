{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPuRO6erHgrUErTssSNFs9C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvanFXPro/Mestrado/blob/main/TestCodeClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando las librerías necesarias y módulos\n",
        "import os  # os permite interactuar con el sistema operativo\n",
        "import pandas as pd  # pandas es usado para manipulación de datos\n",
        "import numpy as np  # numpy es usado para cálculos numéricos\n",
        "import tensorflow as tf  # tensorflow es una librería de aprendizaje automático\n",
        "import matplotlib.pyplot as plt  # matplotlib se usa para visualización de datos\n",
        "\n",
        "# Importando funcionalidades necesarias de tensorflow y keras\n",
        "from tensorflow.keras.applications import ResNet50  # Modelo ResNet50 para clasificación de imágenes\n",
        "from tensorflow.keras.models import Model  # Clase Model para crear modelos de redes neuronales\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D  # Diferentes capas para usar en la red neuronal\n",
        "from tensorflow.keras.optimizers import Adam  # Optimizador Adam para la compilación del modelo\n",
        "\n",
        "# Importando funcionalidades necesarias de scikit-learn\n",
        "from sklearn.preprocessing import MultiLabelBinarizer  # MultiLabelBinarizer para manejar clasificación multietiqueta\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, hamming_loss  # Métricas para evaluar el rendimiento del modelo\n",
        "import seaborn as sns  # seaborn se usa para una mejor visualización de datos\n",
        "\n",
        "# Importando capas adicionales para usar en el modelo\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Importando funcionalidades necesarias para la evaluación del modelo y división de datos\n",
        "from sklearn.model_selection import train_test_split  # train_test_split para dividir datos en conjuntos de entrenamiento y prueba\n",
        "from sklearn.metrics import classification_report, confusion_matrix  # Métricas adicionales para evaluar el modelo\n",
        "\n",
        "# Importando el modelo VGG16 para la clasificación de imágenes\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "# Importando funcionalidades para la aumentación de datos\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Importando el modelo VGG19 para clasificación de imágenes\n",
        "from keras.applications import VGG19\n",
        "\n",
        "# Importando ResNet50 de nuevo (esto parece redundante y podría eliminarse)\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Importando capas de nuevo (esto parece redundante y podría eliminarse)\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# Importando la clase Model de nuevo (esto parece redundante y podría eliminarse)\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Librería específica de Google Colab para montar Google Drive\n",
        "from google.colab import drive\n"
      ],
      "metadata": {
        "id": "DO1L2w4vRL0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Montando Google Drive en el entorno de ejecución de Colab.\n",
        "# Esto proporcionará acceso directo a los archivos almacenados en Google Drive.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Estableciendo el directorio principal donde se encuentran los datos.\n",
        "# '/content/drive/My Drive/2023/LCData' es la ruta donde están almacenados los datos en Google Drive.\n",
        "main_folder = '/content/drive/My Drive/2023/LCData'\n",
        "\n",
        "# Creando una lista de subcarpetas dentro del directorio principal.\n",
        "# os.listdir(main_folder) devuelve una lista de todos los archivos y carpetas en main_folder.\n",
        "# os.path.isdir(os.path.join(main_folder, f)) verifica si cada elemento es un directorio.\n",
        "# [f for f in os.listdir(main_folder) if os.path.isdir(os.path.join(main_folder, f))] crea una lista de solo las subcarpetas.\n",
        "subfolders = [f for f in os.listdir(main_folder) if os.path.isdir(os.path.join(main_folder, f))]\n"
      ],
      "metadata": {
        "id": "exX6wK-xRTKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializando una lista vacía para almacenar los datos.\n",
        "data = []\n",
        "\n",
        "# Iterando sobre cada subcarpeta dentro de la lista de subcarpetas.\n",
        "for subfolder in subfolders:\n",
        "    # Creando la ruta completa a cada subcarpeta.\n",
        "    subfolder_path = os.path.join(main_folder, subfolder)\n",
        "\n",
        "    # Iterando sobre cada archivo dentro de las subcarpetas.\n",
        "    for image_filename in os.listdir(subfolder_path):\n",
        "        # Verificando si el archivo es una imagen basándonos en la extensión del archivo.\n",
        "        if image_filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "            # Creando la ruta completa a cada imagen.\n",
        "            image_path = os.path.join(subfolder_path, image_filename)\n",
        "            # Añadiendo un diccionario con el nombre de la imagen, la ruta y la etiqueta (nombre de la subcarpeta) a la lista de datos.\n",
        "            data.append({'Name': image_filename, 'Path': image_path, 'Label': subfolder})\n",
        "\n",
        "# Convirtiendo la lista de datos en un DataFrame de pandas para una manipulación más fácil de los datos.\n",
        "df_total = pd.DataFrame(data)\n",
        "\n",
        "# Ajustando las opciones de visualización de pandas para mostrar todas las columnas.\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Imprimiendo el DataFrame para visualizar los datos.\n",
        "print(df_total)"
      ],
      "metadata": {
        "id": "-0kwYSqQRiEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Asignando df_total a original_df para mantener una referencia del DataFrame original\n",
        "# y poder trabajar con una copia sin modificar el DataFrame original.\n",
        "original_df = df_total\n",
        "\n",
        "# Extrayendo todas las etiquetas (columna 'Label') de original_df para su análisis o uso posterior.\n",
        "labels = original_df['Label']\n",
        "\n",
        "print('---------------------------------------------------------------------------------------------')\n",
        "\n",
        "# Calculando y mostrando la frecuencia de cada etiqueta única en el DataFrame.\n",
        "# Es útil para entender la distribución de clases y cuántas muestras hay de cada clase en el conjunto de datos.\n",
        "label_counts = original_df['Label'].value_counts()\n",
        "print(label_counts)\n",
        "\n",
        "# Identificando la clase con la menor cantidad de muestras en el conjunto de datos.\n",
        "# Esto puede ser útil para identificar si alguna clase está subrepresentada y puede necesitar oversampling.\n",
        "min_class_name, min_count = min(label_counts.items(), key=lambda x: x[1])\n",
        "print(\"CLASS \" + str(min_class_name) + \" appears \" + str(min_count) + \" Times \")\n",
        "\n",
        "print('----------------------------------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "WANsiE9ZRoW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creando un diccionario que contiene el número deseado de muestras para cada clase/etiqueta.\n",
        "# Cada clave del diccionario representa una clase/etiqueta (por ejemplo, \"Malignant\", \"Normal\", \"Benign\").\n",
        "# Cada valor asociado representa el número de muestras deseadas para esa clase específica.\n",
        "desired_samples_per_class = {\n",
        "    \"Malignant\": 500,  # Se desean 500 muestras para la clase \"Malignant\".\n",
        "    \"Normal\": 400,     # Se desean 400 muestras para la clase \"Normal\".\n",
        "    \"Bengin\": 100,     # Se desean 100 muestras para la clase \"Benign\".\n",
        "}\n"
      ],
      "metadata": {
        "id": "vBW8z_xfRq-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creando un nuevo DataFrame vacío llamado balanced_df.\n",
        "# Este DataFrame se utilizará posteriormente para almacenar las muestras de cada clase/etiqueta,\n",
        "# asegurando que el conjunto de datos esté balanceado según el número de muestras deseadas\n",
        "# definidas previamente en desired_samples_per_class.\n",
        "balanced_df = pd.DataFrame()\n"
      ],
      "metadata": {
        "id": "6d-gTVgPeT0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterando sobre cada etiqueta/clase y el número de muestras deseadas de desired_samples_per_class.\n",
        "for label, num_samples in desired_samples_per_class.items():\n",
        "    # Seleccionando un subconjunto del DataFrame original que corresponde a la etiqueta/clase actual.\n",
        "    class_subset = original_df[original_df['Label'] == label]\n",
        "\n",
        "    # Muestreando aleatoriamente el número deseado de muestras de cada clase.\n",
        "    # 'random_state=42' asegura que la aleatoriedad sea reproducible y obtengamos los mismos resultados en cada ejecución.\n",
        "    sampled_subset = class_subset.sample(n=num_samples, random_state=42)\n",
        "\n",
        "    # Concatenando el subconjunto muestreado al DataFrame balanceado.\n",
        "    # 'ignore_index=False' mantiene los índices originales del DataFrame. Si se prefiere reiniciar los índices, se puede cambiar a True.\n",
        "    balanced_df = pd.concat([balanced_df, sampled_subset], ignore_index=False)"
      ],
      "metadata": {
        "id": "cxpS85L2ebr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extrayendo las etiquetas del DataFrame balanceado para su posterior análisis o uso.\n",
        "labels = balanced_df['Label']\n",
        "\n",
        "# Contando la cantidad de ocurrencias de cada etiqueta única en el DataFrame balanceado\n",
        "# Esto es útil para verificar si el DataFrame ha sido balanceado correctamente.\n",
        "label_counts = balanced_df['Label'].value_counts()\n",
        "\n",
        "# Imprimiendo las cuentas de etiquetas para visualizar la distribución de las muestras entre diferentes clases/etiquetas.\n",
        "print(label_counts)\n"
      ],
      "metadata": {
        "id": "3GC-9_o5ekku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificando los índices que están presentes en el DataFrame original pero no en el DataFrame balanceado.\n",
        "# Esto se hace para encontrar las muestras que no se han utilizado durante el balanceo.\n",
        "unused_indices = original_df.index.difference(balanced_df.index)\n",
        "\n",
        "# Creando un nuevo DataFrame, mytest_df, que contiene solo las muestras no utilizadas.\n",
        "# Estas muestras se pueden usar para testing u otros propósitos, ya que no están presentes en el DataFrame balanceado.\n",
        "mytest_df = original_df.loc[unused_indices]\n",
        "\n",
        "# Contando la cantidad de ocurrencias de cada etiqueta única en el nuevo DataFrame (mytest_df).\n",
        "# Esto es útil para entender la distribución de las etiquetas en el conjunto de datos no utilizado.\n",
        "label_counts = mytest_df['Label'].value_counts()\n",
        "\n",
        "# Imprimiendo las cuentas de etiquetas para visualizar la cantidad de muestras no utilizadas de cada clase/etiqueta.\n",
        "print(label_counts)\n"
      ],
      "metadata": {
        "id": "kXhpInVgexZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Restableciendo los índices del DataFrame balanced_df.\n",
        "# El parámetro drop=True descarta la columna de índice actual en lugar de mantenerla como una columna separada.\n",
        "# El parámetro inplace=True modifica el DataFrame original y no devuelve un nuevo objeto DataFrame.\n",
        "balanced_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Realizando el mismo proceso de restablecimiento de índices para el DataFrame mytest_df.\n",
        "# Esto asegura que ambos DataFrames tengan índices limpios y consecutivos después de las operaciones previas.\n",
        "mytest_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "Zw37vWl8e4Vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividiendo el DataFrame balanceado en conjuntos de entrenamiento y validación.\n",
        "# test_size=0.2: El 20% de los datos se reservan para el conjunto de validación, y el 80% restante se usa para entrenamiento.\n",
        "# random_state=42: Asegura que la división sea reproducible al usar una semilla específica para el generador de números aleatorios.\n",
        "# stratify=balanced_df['Label']: Asegura que la distribución de las etiquetas/clases sea similar tanto en los conjuntos de entrenamiento como de validación,\n",
        "#                                manteniendo las proporciones de las diferentes clases.\n",
        "train_df2, valid_df2 = train_test_split(balanced_df, test_size=0.2, random_state=42, stratify=balanced_df['Label'])"
      ],
      "metadata": {
        "id": "YNp9Ozlje_ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el tamaño de las imágenes que se usarán en el modelo.\n",
        "# Esto es importante para asegurarse de que todas las imágenes tengan las mismas dimensiones.\n",
        "image_size = (224, 224)  # Adjust this size as needed\n",
        "\n",
        "# Definir el tamaño del lote o 'batch'.\n",
        "# Esto se refiere al número de ejemplos de entrenamiento utilizados en cada iteración para actualizar los pesos del modelo.\n",
        "batch_size = 32\n",
        "\n",
        "# Crear un generador de imágenes. Esto ayudará a preprocesar las imágenes antes de alimentarlas al modelo.\n",
        "# En este caso, las imágenes se están normalizando, dividiéndolas por 255 para que los píxeles estén entre 0 y 1.\n",
        "datagen_level2 = ImageDataGenerator(rescale=1.0/255.0)  # Normalize pixel values\n",
        "\n",
        "# Configurar el generador de datos de entrenamiento.\n",
        "# Este generador tomará un DataFrame como input y generará lotes de imágenes preprocesadas y etiquetas correspondientes.\n",
        "train_generator_level2 = datagen_level2.flow_from_dataframe(\n",
        "    train_df2,  # DataFrame que contiene los datos de entrenamiento\n",
        "    x_col=\"Path\",  # Columna en el DataFrame que contiene la ruta de las imágenes\n",
        "    y_col=\"Label\",  # Columna en el DataFrame que contiene las etiquetas de las imágenes\n",
        "    target_size=image_size,  # Tamaño al cual se redimensionarán las imágenes\n",
        "    batch_size=batch_size,  # Número de ejemplos en cada lote\n",
        "    class_mode=\"categorical\"  # Modo de las etiquetas. En este caso, las etiquetas se consideran categóricas (más de 2 clases)\n",
        ")\n",
        "\n",
        "# Configurar el generador de datos de validación de manera similar al generador de datos de entrenamiento.\n",
        "validation_generator_level2 = datagen_level2.flow_from_dataframe(\n",
        "    valid_df2,\n",
        "    x_col=\"Path\",\n",
        "    y_col=\"Label\",\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "# Configurar el generador de datos de prueba. Esto se utilizará para evaluar el modelo después del entrenamiento.\n",
        "testsubset_df=mytest_df\n",
        "test_generator_level2 = datagen_level2.flow_from_dataframe(\n",
        "    testsubset_df,\n",
        "    x_col=\"Path\",\n",
        "    y_col=\"Label\",\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\"\n",
        ")"
      ],
      "metadata": {
        "id": "me6ItNWufDTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aquí estamos obteniendo las etiquetas de las clases del generador de entrenamiento.\n",
        "# Multiclass_labels almacenará un diccionario donde las claves son los nombres de las clases (etiquetas)\n",
        "# y los valores son los índices numéricos correspondientes asignados a cada clase única durante el flujo de datos.\n",
        "# Esto es útil para tener una referencia de qué índice numérico corresponde a cada clase/etiqueta cuando estamos\n",
        "# trabajando con un problema de clasificación multiclase.\n",
        "Multiclass_labels = train_generator_level2.class_indices"
      ],
      "metadata": {
        "id": "_G2XnSW2fIWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aquí se inicializa el modelo base usando ResNet50 preentrenado en ImageNet\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# A continuación, construimos la parte superior personalizada del modelo\n",
        "x = base_model.output  # Obtiene la salida del modelo base\n",
        "x = GlobalAveragePooling2D()(x)  # Añade una capa de agrupamiento global promedio\n",
        "x = Dense(128, activation='relu')(x)  # Añade una capa densa con 128 nodos y activación relu\n",
        "# Aquí, definimos la capa de salida con tantos nodos como etiquetas y activación softmax\n",
        "predictions_level2 = Dense(len(Multiclass_labels), activation='softmax')(x)\n",
        "# Ahora, combinamos el modelo base y las capas superiores personalizadas en un modelo completo\n",
        "multiclass_model1 = Model(inputs=base_model.input, outputs=predictions_level2)\n",
        "\n",
        "# En esta parte, hacemos que las capas del modelo base sean no entrenables\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compilamos el modelo, especificando el optimizador, la función de pérdida y las métricas para monitorear\n",
        "multiclass_model1.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                         loss='categorical_crossentropy',\n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "# Finalmente, ajustamos el modelo a los datos de entrenamiento y validación, especificando el número de épocas\n",
        "history1 = multiclass_model1.fit(train_generator_level2,\n",
        "                                validation_data=validation_generator_level2,\n",
        "                                epochs=10)"
      ],
      "metadata": {
        "id": "GU5Lg492fOFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizando VGG16 como modelo base preentrenado\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Añadiendo capas personalizadas para adaptar la salida del modelo base a nuestras necesidades\n",
        "x = base_model.output\n",
        "x=MaxPooling2D(pool_size=(3, 3))(x)  # Añadiendo una capa de MaxPooling\n",
        "x = GlobalAveragePooling2D()(x)  # Añadiendo una capa de GlobalAveragePooling\n",
        "x = Dense(128, activation='relu')(x)  # Añadiendo una capa densa con activación relu\n",
        "# Añadiendo una capa de salida con tantas unidades como clases y activación softmax\n",
        "predictions_level2 = Dense(len(Multiclass_labels), activation='softmax')(x)\n",
        "\n",
        "# Creando el modelo final que será entrenado\n",
        "multiclass_model2 = Model(inputs=base_model.input, outputs=predictions_level2)"
      ],
      "metadata": {
        "id": "qkfaC_cbgNHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En este segmento de código, estamos configurando las capas del modelo base para que no sean entrenables.\n",
        "# Esto significa que los pesos de estas capas no se actualizarán durante el entrenamiento.\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# A continuación, compilamos el modelo. Esto prepara el modelo para el entrenamiento.\n",
        "# Se especifica el optimizador 'adam', la función de pérdida 'categorical_crossentropy' y\n",
        "# la métrica 'accuracy' que queremos monitorear.\n",
        "multiclass_model2.compile(optimizer='adam',\n",
        "                         loss='categorical_crossentropy',\n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "# Aquí, estamos ajustando el modelo a los datos. Específicamente, estamos entrenando el modelo\n",
        "# usando un generador de datos, lo que significa que los datos se generarán y alimentarán al modelo\n",
        "# en tiempo real. También estamos especificando datos de validación y el número de épocas\n",
        "# que queremos que se ejecute el entrenamiento.\n",
        "history2 = multiclass_model2.fit(train_generator_level2,\n",
        "                                validation_data=validation_generator_level2,\n",
        "                                epochs=10)\n"
      ],
      "metadata": {
        "id": "W5Wi9x_Ygi-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizando VGG19 como modelo base preentrenado\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Añadiendo capas personalizadas para adaptar la salida del modelo base a nuestras necesidades\n",
        "x = base_model.output\n",
        "x=MaxPooling2D(pool_size=(2, 2))(x)  # Añadiendo una capa de MaxPooling\n",
        "x = GlobalAveragePooling2D()(x)  # Añadiendo una capa de GlobalAveragePooling\n",
        "\n",
        "x = Dense(128, activation='relu')(x)  # Añadiendo una capa densa con activación relu\n",
        "# Añadiendo una capa de salida con tantas unidades como clases y activación softmax\n",
        "predictions_level2 = Dense(len(Multiclass_labels), activation='softmax')(x)\n",
        "\n",
        "# Creando el modelo final que será entrenado\n",
        "multiclass_model3 = Model(inputs=base_model.input, outputs=predictions_level2)\n",
        "\n",
        "# Asegurando que las capas del modelo base no serán entrenadas\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compilando el modelo con el optimizador adam, y configurándolo para clasificación multiclase\n",
        "multiclass_model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Iniciando el entrenamiento del modelo utilizando los datos generados y validándolo también.\n",
        "history3 = multiclass_model3.fit(train_generator_level2, validation_data=validation_generator_level2, epochs=10)"
      ],
      "metadata": {
        "id": "ptQUMFGcg71k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creando una figura para visualizar la precisión y la pérdida durante el entrenamiento\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "# Subgráfico para la precisión durante el entrenamiento\n",
        "plt.subplot(1, 2, 1)\n",
        "# Graficando la precisión de entrenamiento y validación del modelo con ResNet\n",
        "plt.plot(history1.history['accuracy'], label='Training Accuracy Resnet')\n",
        "plt.plot(history1.history['val_accuracy'], label='Validation Accuracy Resnet')\n",
        "# Graficando la precisión de entrenamiento y validación del modelo con VGG16\n",
        "plt.plot(history2.history['accuracy'], label='Training Accuracy VGG16')\n",
        "plt.plot(history2.history['val_accuracy'], label='Validation Accuracy VGG16')\n",
        "# Las líneas para VGG19 están comentadas, se pueden descomentar si se desea visualizar\n",
        "#plt.plot(history3.history['accuracy'], label='Training Accuracy VGG19')\n",
        "#plt.plot(history3.history['val_accuracy'], label='Validation Accuracy VGG19')\n",
        "\n",
        "plt.xlabel('Epoch')  # Etiqueta del eje x\n",
        "plt.ylabel('Accuracy')  # Etiqueta del eje y\n",
        "plt.legend()  # Añadiendo la leyenda para identificar cada línea\n",
        "\n",
        "# Subgráfico para la pérdida durante el entrenamiento\n",
        "plt.subplot(1, 2, 2)\n",
        "# Graficando la pérdida de entrenamiento y validación del modelo con ResNet\n",
        "plt.plot(history1.history['loss'], label='Training Loss Resnet')\n",
        "plt.plot(history1.history['val_loss'], label='Validation Loss Resnet')\n",
        "# Graficando la pérdida de entrenamiento y validación del modelo con VGG16\n",
        "plt.plot(history2.history['loss'], label='Training Loss VGG16')\n",
        "plt.plot(history2.history['val_loss'], label='Validation Loss VGG16')\n",
        "# Las líneas para VGG19 están comentadas, se pueden descomentar si se desea visualizar\n",
        "#plt.plot(history3.history['loss'], label='Training Loss VGG19')\n",
        "#plt.plot(history3.history['val_loss'], label='Validation Loss VGG19')\n",
        "\n",
        "plt.xlabel('Epoch')  # Etiqueta del eje x\n",
        "plt.ylabel('Loss')  # Etiqueta del eje y\n",
        "plt.legend()  # Añadiendo la leyenda para identificar cada línea\n",
        "\n",
        "plt.show()  # Mostrando la figura"
      ],
      "metadata": {
        "id": "Fhrm230GmOpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluando el modelo multiclase basado en ResNet en el conjunto de datos de prueba\n",
        "loss1, accuracy1 = multiclass_model1.evaluate(test_generator_level2)\n",
        "\n",
        "# Imprimiendo la pérdida y la precisión del modelo\n",
        "print(f\"Test Loss for Resnet: {loss1:.4f}\")  # Imprime la pérdida con 4 decimales\n",
        "print(f\"Test Accuracy for Resnet: {accuracy1 * 100:.2f}%\")  # Imprime la precisión como un porcentaje con 2 decimales"
      ],
      "metadata": {
        "id": "FmSWurjSmVvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = []  # Inicialización de la lista para las etiquetas verdaderas\n",
        "predicted_labels = []  # Inicialización de la lista para las etiquetas predichas\n",
        "from tensorflow.keras.preprocessing import image  # Importando el módulo necesario para procesamiento de imágenes"
      ],
      "metadata": {
        "id": "bIiCmm1Fma-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición de una función para preprocesar las imágenes antes de alimentarlas al modelo.\n",
        "# La función toma la ruta de una imagen como entrada.\n",
        "def preprocess_image(image_path):\n",
        "    # Cargando la imagen de la ruta especificada y ajustando su tamaño a 224x224 píxeles.\n",
        "    # 224x224 es una dimensión comúnmente usada para modelos preentrenados.\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "\n",
        "    # Convirtiendo la imagen cargada en un array de numpy para poder manipularla y procesarla.\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    # Añadiendo una dimensión adicional que representa el tamaño del batch.\n",
        "    # Esto es necesario porque muchos modelos de Keras esperan datos con una dimensión de batch.\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Normalizando los valores de los píxeles de la imagen para que estén entre 0 y 1.\n",
        "    # Esto es una práctica común que ayuda a mejorar la convergencia durante el entrenamiento.\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    # Retornando el array de la imagen preprocesada.\n",
        "    return img_array\n",
        "\n",
        "\n",
        "# Inicializando dos listas vacías para almacenar las etiquetas verdaderas y las etiquetas predichas\n",
        "# de las imágenes cuando sean procesadas y evaluadas por un modelo.\n",
        "true_labels = []        # Esta lista almacenará las etiquetas verdaderas/reales de las imágenes.\n",
        "predicted_labels = []   # Esta lista almacenará las etiquetas que el modelo prediga."
      ],
      "metadata": {
        "id": "In0ZHA6fm3i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterando sobre cada fila en el DataFrame testsubset_df, que asumimos contiene información sobre imágenes y sus etiquetas.\n",
        "for index, row in testsubset_df.iterrows():\n",
        "    # Obteniendo la ruta de la imagen y la etiqueta de la fila actual del DataFrame.\n",
        "    filename = row['Path']\n",
        "    label = row['Label']\n",
        "\n",
        "    # Utilizando la función de preprocesamiento definida previamente para preparar la imagen para la predicción.\n",
        "    img_array = preprocess_image(filename)\n",
        "\n",
        "    # Realizando predicciones con el modelo multiclase preentrenado.\n",
        "    # Las predicciones resultantes son probabilidades para cada clase.\n",
        "    multi_class_predictions = multiclass_model1.predict(img_array)\n",
        "\n",
        "    # Identificando el índice de la clase con la mayor probabilidad predicha.\n",
        "    sub_class_index = np.argmax(multi_class_predictions)\n",
        "\n",
        "    # Buscando el nombre de la clase correspondiente al índice identificado.\n",
        "    sub_class_name = [k for k, v in train_generator_level2.class_indices.items() if v == sub_class_index][0]\n",
        "\n",
        "    # Imprimiendo el nombre de la clase detectada y el índice actual de la iteración.\n",
        "    print(f\"Detected-class: \" + sub_class_name)\n",
        "    print(index)\n",
        "\n",
        "    # Añadiendo el nombre de la clase predicha a la lista de etiquetas predichas.\n",
        "    predicted_labels.append(sub_class_name)\n",
        "\n",
        "    # Añadiendo la etiqueta real de la imagen a la lista de etiquetas verdaderas.\n",
        "    true_labels.append(label)"
      ],
      "metadata": {
        "id": "rFXnTHVom-Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generando una matriz de confusión usando las etiquetas verdaderas y las etiquetas predichas.\n",
        "# Esta matriz ayuda a entender cómo se distribuyen las predicciones reales vs. las predicciones del modelo.\n",
        "confusion_matrix_subclasses_abnormal = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Calculando la precisión integrada multi-clase.\n",
        "# Es el porcentaje de predicciones correctas con respecto a todas las predicciones.\n",
        "IntegratedMultiAcc = (np.trace(confusion_matrix_subclasses_abnormal) / np.sum(confusion_matrix_subclasses_abnormal)) * 100\n",
        "\n",
        "# Extrayendo los nombres de las etiquetas de clases del generador de entrenamiento.\n",
        "# Esto es útil para etiquetar los ejes en la visualización de la matriz de confusión.\n",
        "class_labels = [label for label in train_generator_level2.class_indices]\n",
        "\n",
        "# Visualizando la matriz de confusión usando seaborn.\n",
        "plt.figure(figsize=(8, 6))  # Estableciendo el tamaño de la figura.\n",
        "\n",
        "# Dibujando un mapa de calor (heatmap) para representar la matriz de confusión.\n",
        "# Los números reales (annot=True) se muestran en cada celda, y se utiliza una paleta de colores azules.\n",
        "sns.heatmap(confusion_matrix_subclasses_abnormal, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_labels, yticklabels=class_labels)\n",
        "\n",
        "# Etiquetando los ejes y dando un título al gráfico.\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Resnet Multi_Class Inside Abnormal Accuracy=' + str(IntegratedMultiAcc))\n",
        "\n",
        "# Mostrando el gráfico.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "USwlPrHFnTOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluando el rendimiento del modelo multiclass_model2 en el conjunto de prueba.\n",
        "# La función 'evaluate' devuelve la pérdida y la precisión del modelo en el conjunto de datos proporcionado.\n",
        "loss2, accuracy2 = multiclass_model2.evaluate(test_generator_level2)\n",
        "\n",
        "# Imprimiendo la pérdida obtenida en el conjunto de prueba para el modelo VGG16.\n",
        "print(f\"Test Loss for VGG16: {loss2:.4f}\")\n",
        "\n",
        "# Imprimiendo la precisión obtenida en el conjunto de prueba para el modelo VGG16.\n",
        "# La precisión se multiplica por 100 para convertirla en un porcentaje.\n",
        "print(f\"Test Accuracy for VGG16: {accuracy2 * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "eraQdFxonYM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializando dos listas vacías para almacenar las etiquetas verdaderas y las etiquetas predichas.\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Importando la función 'image' de tensorflow.keras.preprocessing para cargar y preprocesar imágenes.\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Definiendo una función para preprocesar las imágenes antes de alimentarlas al modelo para la predicción.\n",
        "def preprocess_image(image_path):\n",
        "    # Cargando la imagen del path especificado y ajustando su tamaño a 224x224 píxeles.\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "\n",
        "    # Convirtiendo la imagen cargada en un array de numpy.\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    # Expandiendo las dimensiones del array de la imagen, añadiendo una dimensión para el batch size.\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Normalizando los valores de los píxeles de la imagen para que estén entre 0 y 1.\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    return img_array  # Retornando el array de la imagen preprocesada.\n",
        "\n",
        "# Reinicializando las listas de etiquetas verdaderas y etiquetas predichas (esto podría ser necesario si\n",
        "# desea reutilizar las listas y asegurarse de que estén vacías al principio).\n",
        "true_labels = []\n",
        "predicted_labels = []"
      ],
      "metadata": {
        "id": "bUH9uu9angkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterando a través de cada fila en el dataframe testsubset_df.\n",
        "for index, row in testsubset_df.iterrows():\n",
        "    # Obteniendo el nombre del archivo (path completo) y la etiqueta de la imagen actual.\n",
        "    filename = row['Path']\n",
        "    label = row['Label']\n",
        "\n",
        "    # Preprocesando la imagen usando la función definida anteriormente.\n",
        "    img_array = preprocess_image(filename)\n",
        "\n",
        "    # Realizando la predicción utilizando el modelo multiclase.\n",
        "    # Esto nos da una lista de probabilidades para cada clase.\n",
        "    multi_class_predictions = multiclass_model2.predict(img_array)\n",
        "\n",
        "    # Identificando el índice de la clase con la probabilidad más alta en las predicciones.\n",
        "    sub_class_index = np.argmax(multi_class_predictions)\n",
        "\n",
        "    # Buscando el nombre de la clase que corresponde al índice identificado.\n",
        "    sub_class_name = [k for k, v in train_generator_level2.class_indices.items() if v == sub_class_index][0]\n",
        "\n",
        "    # Imprimiendo la clase detectada y el índice actual en el dataframe.\n",
        "    print(f\"Detected-class: \" + sub_class_name)\n",
        "    print(index)\n",
        "\n",
        "    # Añadiendo la clase predicha a la lista de etiquetas predichas.\n",
        "    predicted_labels.append(sub_class_name)\n",
        "\n",
        "    # Añadiendo la etiqueta verdadera a la lista de etiquetas verdaderas.\n",
        "    true_labels.append(label)"
      ],
      "metadata": {
        "id": "R4ZddacSnpJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculando la matriz de confusión utilizando las etiquetas verdaderas y las etiquetas predichas.\n",
        "confusion_matrix_subclasses_abnormal = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Calculando la precisión integrada multi-clase como el porcentaje de predicciones correctas.\n",
        "IntegratedMultiAcc = (np.trace(confusion_matrix_subclasses_abnormal) / np.sum(confusion_matrix_subclasses_abnormal)) * 100\n",
        "\n",
        "# Obteniendo las etiquetas de las clases del generador.\n",
        "class_labels = [label for label in train_generator_level2.class_indices]\n",
        "\n",
        "# Creando una figura para visualizar la matriz de confusión.\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Creando un mapa de calor para la matriz de confusión usando seaborn.\n",
        "# Anotaciones se habilitan y el formato se establece como decimal.\n",
        "sns.heatmap(confusion_matrix_subclasses_abnormal, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_labels, yticklabels=class_labels)\n",
        "\n",
        "# Etiquetando los ejes x e y del mapa de calor.\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "\n",
        "# Añadiendo un título a la figura que muestra la precisión integrada multi-clase.\n",
        "plt.title('VGG16-Multi_Class Inside Abnormal Accuracy=' + str(IntegratedMultiAcc))\n",
        "\n",
        "# Mostrando la figura.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r2vLtvPTnvjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluando el modelo multiclase (multiclass_model3) usando el conjunto de datos de prueba (test_generator_level2).\n",
        "# Esto devolverá la pérdida y la precisión del modelo en el conjunto de datos de prueba.\n",
        "loss3, accuracy3 = multiclass_model3.evaluate(test_generator_level2)\n",
        "\n",
        "# Imprimiendo la pérdida y la precisión del modelo en el conjunto de datos de prueba.\n",
        "# La pérdida se muestra con 4 decimales y la precisión se muestra como un porcentaje con 2 decimales.\n",
        "print(f\"Test Loss for VGG19: {loss3:.4f}\")\n",
        "print(f\"Test Accuracy for VGG19: {accuracy3 * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "P1zRD5GLnz5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializando listas vacías para almacenar las etiquetas verdaderas y las etiquetas predichas.\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Importando la función image del módulo de preprocesamiento de keras.\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Definiendo una función para preprocesar las imágenes.\n",
        "def preprocess_image(image_path):\n",
        "    # Cargando la imagen del path especificado y ajustándola al tamaño 224x224.\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "\n",
        "    # Convirtiendo la imagen cargada en un array.\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    # Expandiendo las dimensiones del array de la imagen, añadiendo una dimensión para el batch.\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Añadiendo dimensión de batch\n",
        "\n",
        "    # Normalizando los valores de los píxeles de la imagen para que estén entre 0 y 1.\n",
        "    img_array = img_array / 255.0  # Normalizando valores de píxeles\n",
        "\n",
        "    return img_array  # Retornando el array de la imagen preprocesada.\n",
        "\n",
        "# Re-inicializando las listas de etiquetas verdaderas y predichas, asegurándose de que estén vacías.\n",
        "true_labels = []\n",
        "predicted_labels = []"
      ],
      "metadata": {
        "id": "_2FAlwNCn6lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterando sobre cada fila en el dataframe testsubset_df.\n",
        "for index, row in testsubset_df.iterrows():\n",
        "        # Obteniendo el nombre del archivo (path) y la etiqueta real de la imagen.\n",
        "        filename = row['Path']\n",
        "        label = row['Label']\n",
        "\n",
        "        # Preprocesando la imagen usando la función previamente definida.\n",
        "        img_array = preprocess_image(filename)\n",
        "\n",
        "        # Obteniendo las predicciones del modelo para la imagen preprocesada.\n",
        "        multi_class_predictions = multiclass_model3.predict(img_array)\n",
        "\n",
        "        # Identificando el índice de la clase con la mayor probabilidad predicha.\n",
        "        sub_class_index = np.argmax(multi_class_predictions)  # Elegir la sub-clase con la mayor probabilidad\n",
        "\n",
        "        # Obteniendo el nombre de la clase correspondiente al índice identificado.\n",
        "        sub_class_name = [k for k, v in train_generator_level2.class_indices.items() if v == sub_class_index][0]\n",
        "\n",
        "        # Imprimiendo la clase detectada y el índice de la fila actual.\n",
        "        print(f\"Detected-class: \" +sub_class_name)  # Añadir 1 al índice para coincidir con sus etiquetas de clase\n",
        "        print(index)\n",
        "\n",
        "        # Añadiendo las etiquetas predichas y reales a las listas correspondientes.\n",
        "        predicted_labels.append(sub_class_name)\n",
        "        true_labels.append(label)"
      ],
      "metadata": {
        "id": "S0x78xoMn-fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculando la matriz de confusión entre las etiquetas verdaderas y las predicciones\n",
        "confusion_matrix_subclasses_abnormal = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Calculando la precisión integrada multi-clase, que es la suma de la diagonal (verdaderos positivos)\n",
        "# de la matriz de confusión dividida por el total de predicciones.\n",
        "IntegratedMultiAcc = (np.trace(confusion_matrix_subclasses_abnormal) / np.sum(confusion_matrix_subclasses_abnormal)) * 100\n",
        "\n",
        "# Obteniendo las etiquetas de las clases del generador de datos para entrenamiento.\n",
        "class_labels = [label for label in train_generator_level2.class_indices]\n",
        "\n",
        "# Creando una figura para visualizar la matriz de confusión\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Visualizando la matriz de confusión como un mapa de calor usando seaborn\n",
        "sns.heatmap(confusion_matrix_subclasses_abnormal, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "\n",
        "# Etiquetando los ejes x e y\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "\n",
        "# Titulando la visualización con la precisión calculada anteriormente\n",
        "plt.title('VGG19-Multi_Class Inside Abnormal Accuracy=' + str(IntegratedMultiAcc))\n",
        "\n",
        "# Mostrando la visualización\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CvxVHXRnocli"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}